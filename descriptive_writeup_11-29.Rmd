---
title: "Descriptive Writeup"
output: 
  html_document:
    toc: true
date: "2023-11-29"
---

```{r, include=FALSE}
library(tidyverse)
library(sf)
library(leaflet)
sat <- read_csv("sat.csv")
sat1 <- sat %>% filter(`Data Source` == "declass1")
sat2 <- sat %>% filter(`Data Source` == "declass2")
sat3 <- sat %>% filter(`Data Source` == "declass3")
```


This document contains some overall description of the various declassified satellite imagery datasets that I've been playing around with for the last few months. They were downloaded from https://earthexplorer.usgs.gov/. 


# Description
### Total Images
The dataset consists of 837,088 images taken between 1960 and 1984 by 5 different satellite systems (see Appendix A for more information about the different datasets). 

The following plot shows the temporal distribution of photos, broken down by data source.

```{r}
n_pics_per_year_grouped <- sat %>% mutate(`Year` = as.numeric(substr(`Acquisition Date`,1,4))) %>%
  group_by(Year, `Data Source`) %>%
  summarise(n_pics = n())

n_pics_per_year_grouped %>%
  ggplot(aes(x = Year)) +
  geom_area(aes(y = n_pics, fill = `Data Source`), 
              alpha = 0.9) + 
  scale_fill_manual(values = c("declass1" = "#7eb0d5", "declass2" = "#fd7f6f", "declass3" = "#01A66F")) +
  ylab("Number of Pictures")
```

### Average Image Footprint
It's worth mentioning that the *types* of images available vary widely both within and across datasets. To take just one dimension of variation, here is the average footprint of photos for each dataset:

```{r}
sat_sf <- st_as_sf(sat, wkt = "geometry")
sat_sf$area <- st_area(sat_sf)

sat_sf_trimmed <- sat_sf %>%
  filter(area != 0)

avgs <- sat_sf_trimmed %>%
  st_drop_geometry() %>%
  as.data.frame() %>%
  group_by(`Data Source`) %>%
  summarise(avg_area = mean(area))

# Calculate the average area of the geometries
mean(sat_sf_trimmed$area) # ~3.22, or about 69*69*3.22 = 15330 sq miles

avgs %>%
  ggplot(aes(x = `Data Source`, y = avg_area)) +
  geom_col(fill = c("declass1" = "#7eb0d5", "declass2" = "#fd7f6f", "declass3" = "#01A66F")) +
  ylab("Average Area (in lat/lng units)")
```

Many of the frames--especially from the earlier programs in `declass1`--have truly massive footprints. The unit is "square lat/long points," which is a bit of an imprecise unit, but which I think corresponds to roughly 69*69 = ~ 4800 square miles. The overall average size for an image frame in the dataset is thus about 15,000 square miles.

### Capture Coverage
What we really care about is when these satellite images contain nuclear targets, such as facilities. By cross-referencing with the coordinates from dataset of facilities that Quido collated, we can get a rough count of which facilities have been photographed (acknowledging that many of these "capture occurences" may be false positives). See Appendix B for more on how captures were counted.

```{r, include = FALSE}
facs <- read_csv("facilities.csv")[-1]
fac_caps_no_unknown <- read_csv("fac_captures.csv")[-1]
fac_caps_with_unknown <- read_csv("fac_caps_with_unknown.csv")[-1]
```


Here is the facility coverage chart, which you've already seen.
#### Calculate and Plot Facility Coverage
```{r}
# Build coverage DF
get_coverage <- function(facs, fac_caps, counting_unknown) {
  coverage <- data.frame(year = integer(),
                         num_extant_facilities = integer(),
                         num_spotted_facilities = integer(),
                         coverage = double())
  
  spotted <- c()
  
  
  # get date range
  min_date = min(facs$start_date, na.rm = TRUE)
  max_date = max(facs$start_date, na.rm = TRUE)
  
  
  # replace NA with 1900 if we want to include NAs in analysis
  if(counting_unknown) {
    facs <- facs %>%
      mutate(start_date = ifelse(is.na(start_date), as.Date("1900-01-01"), start_date))
  }
  
  # loop thru years
  for (year in as.integer(format(min_date, "%Y")):as.integer(format(max_date, "%Y"))) {
    year_date <- as.Date(paste(year, "-01-01", sep = ""))
  
    # extant facilities
    fac_exist <- facs %>%
      filter(start_date <= year_date) %>%
      distinct(facility_name)  # Get unique facility names
  
    n_fac_exist <- nrow(fac_exist)
  
    # spotted facilities
    fac_spotted <- fac_caps %>%
      filter(`Acquisition Date` <= year_date) %>%
      distinct(facility_name)  # Get unique facility names
  
    spotted <- unique(append(spotted,fac_spotted$facility_name))
    n_fac_spotted <- length(spotted)
  
    # remove earlier facilities for next loop
    fac_caps <- fac_caps %>%
      filter(`Acquisition Date` > year_date)
  
    coverage <- bind_rows(coverage, data.frame(year = year,
                                               num_extant_facilities = n_fac_exist,
                                               num_spotted_facilities = n_fac_spotted,
                                               coverage = n_fac_spotted / n_fac_exist))
  }
  
  return(coverage)
}
```


This version ignores facilities with unknown start dates:

```{r}
coverage <- get_coverage(facs, fac_caps_no_unknown, counting_unknown=FALSE)

ggplot(coverage, aes(x = year)) +
  geom_ribbon(aes(ymin = 0, ymax = num_extant_facilities, fill = "Extant Facilities"), alpha = 0.75) +
  geom_ribbon(aes(ymin = 0, ymax = num_spotted_facilities, fill = "Spotted Facilities"), alpha = 0.75) +
  scale_fill_manual(values = c("Extant Facilities" = "#7eb0d5", "Spotted Facilities" = "#fd7f6f")) +
  labs(y = "Coverage",
       x = "Year",
       fill = "") +
  theme_minimal()
```


And this version assumes all facilities with unknown start dates were built in 1900:
```{r}
coverage <- get_coverage(facs, fac_caps_with_unknown, counting_unknown=TRUE)

ggplot(coverage, aes(x = year)) +
  geom_ribbon(aes(ymin = 0, ymax = num_extant_facilities, fill = "Extant Facilities"), alpha = 0.75) +
  geom_ribbon(aes(ymin = 0, ymax = num_spotted_facilities, fill = "Spotted Facilities"), alpha = 0.75) +
  scale_fill_manual(values = c("Extant Facilities" = "#7eb0d5", "Spotted Facilities" = "#fd7f6f")) +
  labs(y = "Coverage",
       x = "Year",
       fill = "") +
  theme_minimal()
```

### Total Capture Activity

By group:
```{r}
fac_caps <- fac_caps_with_unknown %>%
  mutate(`Abbreviated Mission` = substr(Mission,1,4))

caps_by_year_source <- fac_caps %>% 
  group_by(facility_name, `Acquisition Date`, `Abbreviated Mission`, start_date, `Data Source`) %>%
  summarise(n_caps = n()) %>%
  mutate(`Year` = as.numeric(substr(`Acquisition Date`,1,4))) %>%
  group_by(Year, `Data Source`) %>%
  summarise(n_caps = sum(n_caps)) %>%
  ungroup()

caps_by_year_source %>%
  ggplot(aes(x = Year)) +
  geom_col(aes(y = n_caps, fill = `Data Source`), 
              alpha = 0.9) + 
  scale_fill_manual(values = c("declass1" = "#7eb0d5", "declass2" = "#fd7f6f", "declass3" = "#01A66F"))
```

By camera resolution:
```{r}
caps_by_cam <- fac_caps %>% 
  group_by(facility_name, `Acquisition Date`, `Abbreviated Mission`, start_date, `Camera Resolution`) %>%
  summarise(n_caps = n()) %>%
  mutate(`Year` = as.numeric(substr(`Acquisition Date`,1,4))) %>%
  group_by(Year, `Camera Resolution`) %>%
  summarise(n_caps = sum(n_caps)) %>%
  ungroup()

caps_by_cam %>%
  ggplot(aes(x = Year, y = n_caps, fill = `Camera Resolution`)) +
  geom_col()
```

### Per-Facility Visitation
Generate a table with the counts of visits for each facility; visitation leaderboard

```{r, facility_visits}
options(knitr.max.print = 200)

fac_caps <- fac_caps_with_unknown %>%
  mutate(`Abbreviated Mission` = substr(Mission,1,4))

capture_counts <- fac_caps %>% 
  group_by(facility_name, `Acquisition Date`, `Abbreviated Mission`, start_date) %>%
  summarise(n_caps = n()) 

totals <- capture_counts %>%
  ungroup() %>%
  group_by(facility_name) %>%
  summarise(n_caps = sum(n_caps))

missing <- setdiff(unique(facs$facility_name), unique(capture_counts$facility_name))
missing_df <- data.frame(facility_name = missing, n_caps = numeric(9))

totals <- rbind(totals, missing_df)
  
totals <- totals %>%
  arrange(-n_caps)

print(totals, n = 157)
```

And here's a histogram to give a sense of the distribution:

```{r}
totals %>%
  mutate(facility_name = reorder(facility_name,n_caps)) %>%
  ggplot(aes(x = facility_name, y = n_caps)) +
  geom_col() +
  labs(x = NULL, y = "Average Area") + 
  theme(axis.text.x = element_blank())
```


# Appendix A: Satellite Imagery Dataset Overview

## Declassified 1
[Declassified 1](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-1) is the product of a blanket declassification in 1995 and purportedly represents *all* of the images from the following satellite programs:

- CORONA: 1960-1972.

- ARGON: 1962-64

- LANYARD: 1963.

It's not clear which images come from which satellites systems. 

The dataset contains 837088 images. A handful of different camera setups were used during the program:

```{r}
unique(sat1$`Camera Resolution`)
unique(sat1$`Camera Type`)
```

It's not clear how the resolution of these cameras compares to the later generations, KH-7 and KH-9.

Here is the total "footprint" of the images in this dataset (shapefile supplied by USGS):
```{r, include = FALSE}
corona_coverage <- st_read("shps/declass1_shp/corona2.shp")

map <- leaflet() %>%
  addTiles() %>%
  addPolygons(data = corona_coverage)
```

```{r, echo = FALSE}
map
```


## Declassified 2

[Declassified 2](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-2) is the product of a 2002 declassification involving the non-comprehensive declassification of imagery from the following programs:

- KH-7 (GAMBIT): images taken between 1963 and 1967, the full lifespan of GAMBIT.

- KH-9 (HEXAGON): images taken from 1973 to 1980, a subset of the operational period of HEXAGON.

It's not clear whether all of the images from KH-7 were declassified or whether some were withheld. Only a subset of the KH-9 images were declassified. 

The dataset contains 46,699 images. 

KH-7 was used for higher-resolution surveillance. KH-9 had both a lower-resolution mapping camera and a higher-resolution surveillance camera, but only the mapping images were declassified in this declassification act:

```{r}
unique(sat2$`Camera Resolution`)
unique(sat2$`Camera Type`)
```

Here is the total "footprint" of the images in this dataset (shapefile supplied by USGS):
```{r, include = FALSE}
corona_coverage <- st_read("shps/declass2_shp/declassii.shp")

map <- leaflet() %>%
  addTiles() %>%
  addPolygons(data = corona_coverage)
```

```{r, echo = FALSE}
map
```


## Declassified 3

[Declassified 3](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-3) is the product of a 2011 declassification involving the non-comprehensive declassification of imagery from KH-9 (HEXAGON), which ran from 1971 to 1984. This includes images from the high-resolution surveillance camera, but the website says that "almost all of the imagery from these cameras were declassified in 2011" implying that some images remain classified.

The dataset contains 531,321 images. Note that the website says that "The process to ingest and generate browse imagery for Declass-3 is ongoing," and suggests that the HEXAGON program generated over 670,000 scenes, indicating that the dataset which we have access to is missing a substantial chunk of the images from HEXAGON.

Both the terrain mapping and surveillance imagery were included in this declassification:

```{r}
unique(sat3$`Camera Resolution`)
unique(sat3$`Camera Type`)
```

Here is the total "footprint" of the images in this dataset (shapefile supplied by USGS):
```{r, include = FALSE}
corona_coverage <- st_read("shps/declass3_shp/declassiii.shp")

map <- leaflet() %>%
  addTiles() %>%
  addPolygons(data = corona_coverage)
```

```{r, echo = FALSE}
map
```

## Issues with the data
The satellite imagery dataset has a number of limitations.

### Inaccurate & Missing Coordinates
It's not clear that the coordinates listed in the datasets are always accurate. USGS says “We do recommend viewing both the ‘Preview Image’ and ‘Show All Fields’ metadata before submitting your order. Browse viewing is a critical component in the order validation process. The effects of cloud cover and **the accuracy of the latitude and longitude coordinates can greatly affect the usability of the data**." Likewise, the [description of declassified 1](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-1) says "Mathematical calculations based on camera operation and satellite path were used to approximate image coordinates. Since the accuracy of the coordinates varies according to the precision of information used for the derivation, users should inspect the preview image to verify that the area of interest is contained in the selected frame."

Furthermore, 11,409 rows in the dataset (all from declass 2 and 3) simply have no associated coordinates:

```{r}
nrow(filter(sat, geometry == "POLYGON ((0 0,0 0,0 0,0 0,0 0))"))
```

### Missing images & incomplete data
As mentioned above, `declass3` is a work-in-progress; over 100,000 images seem to be missing from it. There are also discrepancies in the number of images advertised for all three datasets on USGS earth explorer and the number that you can actually download, although the result is that you end up with *more* images than expected, not fewer. 

It's also not clear whether some critical images remain classified. [This source](https://nsarchive2.gwu.edu/NSAEBB/NSAEBB392/) indicates that KH-7 images of Isreal are still classified, for instance. The same source also has details on KH-8 or Gambit-3, imagery from which doesn't seem to have been declassified. There are other satellite surveillance programs from the overlapping time periods like GRAB, POPPY, and QUILL, though I haven't looked into which of these were image-takers.

### No Acquisition Date
One particular set of 14 photos from mission 1205-3 in `declass3` has no acquisition date listed.

```{r}
nrow(filter(sat, is.na(`Acquisition Date`)))
```



# Appendix B: Counting Captures

