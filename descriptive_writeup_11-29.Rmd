---
title: "Descriptive Writeup"
output: 
  html_document:
    toc: true
date: "2023-11-29"
runtime: shiny
---

```{r, include=FALSE}
library(tidyverse)
library(sf)
library(leaflet)
sat <- read_csv("sat.csv")
sat1 <- sat %>% filter(`Data Source` == "declass1")
sat2 <- sat %>% filter(`Data Source` == "declass2")
sat3 <- sat %>% filter(`Data Source` == "declass3")
facs <- read_csv("facilities.csv")[-1]

# get date range
min_date = min(sat$`Acquisition Date`, na.rm = TRUE)
max_date = max(sat$`Acquisition Date`, na.rm = TRUE)
```


This document contains some overall description of the various declassified satellite imagery datasets that I've been playing around with for the last few months. They were downloaded from https://earthexplorer.usgs.gov/. 


# Descriptive Statistics
### Total Images
The dataset consists of 837,088 images taken between 1960 and 1984 by 5 different satellite systems (see Appendix A for more information about the different datasets). 

The following plot shows the temporal distribution of photos, broken down by data source.

```{r}
n_pics_per_year_grouped <- sat %>% mutate(`Year` = as.numeric(substr(`Acquisition Date`,1,4))) %>%
  group_by(Year, `Data Source`) %>%
  summarise(n_pics = n())

n_pics_per_year_grouped %>%
  ggplot(aes(x = Year)) +
  geom_area(aes(y = n_pics, fill = `Data Source`), 
              alpha = 0.9) + 
  scale_fill_manual(values = c("declass1" = "#7eb0d5", "declass2" = "#fd7f6f", "declass3" = "#01A66F")) +
  ylab("Number of Pictures")
```

### Average Image Footprint
It's worth mentioning that the *types* of images available vary widely both within and across datasets. To take just one dimension of variation, here is the average footprint of photos for each dataset:

```{r}
sat_sf <- st_as_sf(sat, wkt = "geometry")
sat_sf$area <- st_area(sat_sf)

sat_sf_trimmed <- sat_sf %>%
  filter(area != 0)

avgs <- sat_sf_trimmed %>%
  st_drop_geometry() %>%
  as.data.frame() %>%
  group_by(`Data Source`) %>%
  summarise(avg_area = mean(area))

# Calculate the average area of the geometries
mean(sat_sf_trimmed$area) # ~3.22, or about 69*69*3.22 = 15330 sq miles

avgs %>%
  ggplot(aes(x = `Data Source`, y = avg_area)) +
  geom_col(fill = c("declass1" = "#7eb0d5", "declass2" = "#fd7f6f", "declass3" = "#01A66F")) +
  ylab("Average Area (in lat/lng units)")
```

Many of the frames--especially from the earlier programs in `declass1`--have truly massive footprints. The unit is "square lat/long points," which is a bit of an imprecise unit, but which I think corresponds to roughly 69*69 = ~ 4800 square miles. The overall average size for an image frame in the dataset is thus about 15,000 square miles.


The following tool lets you generate a random sample of image footprints. 

```{r}
library(shiny)

# Define UI for the Shiny app
ui <- fluidPage(
  actionButton("sampleButton", "Re-sample"),
  leafletOutput("map"),
  uiOutput("link")
)

generate_sample <- function(n) {
  return(sample_n(sat_sf_trimmed, n))
}

# Define server logic
server <- function(input, output) {
  # Initial random sample
  sampled_data <- reactive(generate_sample(1))
  
  # Update the sampled data when the button is clicked
  observeEvent(input$sampleButton, {
    sample <- generate_sample(1)
    
    output$map <- renderLeaflet({
      sample <- generate_sample(1)
      
      leaflet() %>%
        addTiles() %>%
        addPolygons(data = sample)
    })
    
    # render link
    output$link <- renderUI({
      get_link(sample)
    })
  })
  
  get_link <- function(sample) {
    pic_url <-""
    
    if(sample$`Data Source` == "declass1") {
        pic_url <- paste("https://earthexplorer.usgs.gov/scene/metadata/full/5e839febdccb64b3/",
                         sample$`Display ID`, sep = "")
        
        #5e839febdccb64b3? 
      } else if(sample$`Data Source` == "declass2") {
        pic_url <- paste("https://earthexplorer.usgs.gov/scene/metadata/full/5e839ff7d71d4811/",
                         sample$`Display ID`, sep = "")
      } else if(sample$`Data Source` == "declass3") {
        pic_url <- paste("https://earthexplorer.usgs.gov/scene/metadata/full/5e7c41f3ffaaf662/",
                         sample$`Display ID`, sep = "")
      }
      
      link <- a("Click to See Image and Metadata", href = pic_url, target="_blank" )
      
      return(link)
  }
  
  output$map <- renderLeaflet({
    sample <- generate_sample(1)
    
    leaflet() %>%
      addTiles() %>%
      addPolygons(data = sample)
  })
    
  # render link
  output$link <- renderUI({
    get_link(sample)
  })
}

# Run the Shiny app
shinyApp(ui, server)
```

```{r}
typical_picture <- sat_sf_trimmed %>% 
  sample_n(25)

str(typical_picture[1])

leaflet() %>%
  addTiles() %>%
  addPolygons(data = typical_picture)
```



## Scratch

Here's a randomly sample of images with roughly that footprint:
```{r}
typical_picture <- sat_sf_trimmed %>% 
  filter(area < 3.23, area > 3.21) %>%
  sample_frac(0.1)

str(typical_picture[1])

leaflet() %>%
  addTiles() %>%
  addPolygons(data = typical_picture)
```



## Calculate and Plot Facility Coverage
```{r}
# fac_caps <- fac_caps_orig
# 
# # Build coverage DF
# coverage <- data.frame(year = integer(),
#                        num_extant_facilities = integer(),
#                        num_spotted_facilities = integer(),
#                        coverage = double())
# 
# spotted <- c()
# 
# # loop thru years
# for (year in as.integer(format(min_date, "%Y")):as.integer(format(max_date, "%Y"))) {
#   year_date <- as.Date(paste(year, "-01-01", sep = ""))
#   
#   # extant facilities
#   fac_exist <- facs %>%
#     filter(start_date <= year_date) %>%
#     distinct(facility_name)  # Get unique facility names
#   
#   n_fac_exist <- nrow(fac_exist)
#   
#   # spotted facilities
#   fac_spotted <- fac_caps %>%
#     filter(`Acquisition Date` <= year_date) %>%
#     distinct(facility_name)  # Get unique facility names
#   
#   spotted <- unique(append(spotted,fac_spotted$facility_name))
#   n_fac_spotted <- length(spotted)
#   
#   # remove earlier facilities for next loop
#   fac_caps <- fac_caps %>% 
#     filter(`Acquisition Date` > year_date)
#   
#   coverage <- bind_rows(coverage, data.frame(year = year,
#                                              num_extant_facilities = n_fac_exist,
#                                              num_spotted_facilities = n_fac_spotted,
#                                              coverage = n_fac_spotted / n_fac_exist))
# }
# 
# ## Plot
# ggplot(coverage, aes(x = year)) +
#   geom_ribbon(aes(ymin = 0, ymax = num_extant_facilities, fill = "Extant Facilities"), alpha = 0.75) +
#   geom_ribbon(aes(ymin = 0, ymax = num_spotted_facilities, fill = "Spotted Facilities"), alpha = 0.75) +
#   scale_fill_manual(values = c("Extant Facilities" = "#7eb0d5", "Spotted Facilities" = "#fd7f6f")) +
#   labs(y = "Coverage", 
#        x = "Year",
#        fill = "") +
#   theme_minimal()
```





# Appendix A: Satellite Imagery Dataset Overview

## Declassified 1
[Declassified 1](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-1) is the product of a blanket declassification in 1995 and purportedly represents *all* of the images from the following satellite programs:

- CORONA: 1960-1972.

- ARGON: 1962-64

- LANYARD: 1963.

It's not clear which images come from which satellites systems. 

The dataset contains 837088 images. A handful of different camera setups were used during the program:

```{r}
unique(sat1$`Camera Resolution`)
unique(sat1$`Camera Type`)
```

It's not clear how the resolution of these cameras compares to the later generations, KH-7 and KH-9.

Here is the total "footprint" of the images in this dataset (shapefile supplied by USGS):
```{r, include = FALSE}
corona_coverage <- st_read("shps/declass1_shp/corona2.shp")

map <- leaflet() %>%
  addTiles() %>%
  addPolygons(data = corona_coverage)
```

```{r, echo = FALSE}
map
```


## Declassified 2

[Declassified 2](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-2) is the product of a 2002 declassification involving the non-comprehensive declassification of imagery from the following programs:

- KH-7 (GAMBIT): images taken between 1963 and 1967, the full lifespan of GAMBIT.

- KH-9 (HEXAGON): images taken from 1973 to 1980, a subset of the operational period of HEXAGON.

It's not clear whether all of the images from KH-7 were declassified or whether some were withheld. Only a subset of the KH-9 images were declassified. 

The dataset contains 46,699 images. 

KH-7 was used for higher-resolution surveillance. KH-9 had both a lower-resolution mapping camera and a higher-resolution surveillance camera, but only the mapping images were declassified in this declassification act:

```{r}
unique(sat2$`Camera Resolution`)
unique(sat2$`Camera Type`)
```

Here is the total "footprint" of the images in this dataset (shapefile supplied by USGS):
```{r, include = FALSE}
corona_coverage <- st_read("shps/declass2_shp/declassii.shp")

map <- leaflet() %>%
  addTiles() %>%
  addPolygons(data = corona_coverage)
```

```{r, echo = FALSE}
map
```


## Declassified 3

[Declassified 3](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-3) is the product of a 2011 declassification involving the non-comprehensive declassification of imagery from KH-9 (HEXAGON), which ran from 1971 to 1984. This includes images from the high-resolution surveillance camera, but the website says that "almost all of the imagery from these cameras were declassified in 2011" implying that some images remain classified.

The dataset contains 531,321 images. Note that the website says that "The process to ingest and generate browse imagery for Declass-3 is ongoing," and suggests that the HEXAGON program generated over 670,000 scenes, indicating that the dataset which we have access to is missing a substantial chunk of the images from HEXAGON.

Both the terrain mapping and surveillance imagery were included in this declassification:

```{r}
unique(sat3$`Camera Resolution`)
unique(sat3$`Camera Type`)
```

Here is the total "footprint" of the images in this dataset (shapefile supplied by USGS):
```{r, include = FALSE}
corona_coverage <- st_read("shps/declass3_shp/declassiii.shp")

map <- leaflet() %>%
  addTiles() %>%
  addPolygons(data = corona_coverage)
```

```{r, echo = FALSE}
map
```

## Issues with the data
The satellite imagery dataset has a number of limitations.

### Inaccurate & Missing Coordinates
It's not clear that the coordinates listed in the datasets are always accurate. USGS says “We do recommend viewing both the ‘Preview Image’ and ‘Show All Fields’ metadata before submitting your order. Browse viewing is a critical component in the order validation process. The effects of cloud cover and **the accuracy of the latitude and longitude coordinates can greatly affect the usability of the data**." Likewise, the [description of declassified 1](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-declassified-data-declassified-satellite-imagery-1) says "Mathematical calculations based on camera operation and satellite path were used to approximate image coordinates. Since the accuracy of the coordinates varies according to the precision of information used for the derivation, users should inspect the preview image to verify that the area of interest is contained in the selected frame."

Furthermore, 11,409 rows in the dataset (all from declass 2 and 3) simply have no associated coordinates:

```{r}
nrow(filter(sat, geometry == "POLYGON ((0 0,0 0,0 0,0 0,0 0))"))
```

### Missing images & incomplete data
As mentioned above, `declass3` is a work-in-progress; over 100,000 images seem to be missing from it. There are also discrepancies in the number of images advertised for all three datasets on USGS earth explorer and the number that you can actually download, although the result is that you end up with *more* images than expected, not fewer. 

It's also not clear whether some critical images remain classified. [This source](https://nsarchive2.gwu.edu/NSAEBB/NSAEBB392/) indicates that KH-7 images of Isreal are still classified, for instance. The same source also has details on KH-8 or Gambit-3, imagery from which doesn't seem to have been declassified. There are other satellite surveillance programs from the overlapping time periods like GRAB, POPPY, and QUILL, though I haven't looked into which of these were image-takers.

### No Acquisition Date
One particular set of 14 photos from mission 1205-3 in `declass3` has no acquisition date listed.

```{r}
nrow(filter(sat, is.na(`Acquisition Date`)))
```



# Appendix B: Counting Captures

