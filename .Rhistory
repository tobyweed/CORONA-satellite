sat2$`Data Source` <- rep("declass2", nrow(sat2))
# reformat Display ID for sat1, sat2 due to bad formatting in CSV provided by USGS
reformat_id <- function(id, n) {
id <- strsplit(id, ",")[[1]][1] # split by comma, take first item
# after the right n of characters insert "-"
new_id <- paste(substr(id, 1, n), "-", substr(id, n+1, nchar(id)), sep = "")
new_id
}
sat1$`Display ID` <- lapply(sat1$`Display ID`, reformat_id, n = 6)
sat2$`Display ID` <- lapply(sat2$`Display ID`, reformat_id, n = 7)
sat1_2 <- rbind(sat1,sat2)
setdiff(colnames(sat1_2), colnames(sat3))
sat3 <- sat3 %>%
mutate(`Camera Type` = str_replace(Camera, "A", "High Resolution Surveillance Camera - Aft")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "F", "High Resolution Surveillance Camera - Forward")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "T", "Lower Resolution Terrain Mapping Camera")) %>%
select(-Camera)
colnames(sat1_2)[colnames(sat1_2) == "Frame"] <- "Frame Number"
colnames(sat1_2)[colnames(sat1) == "Down Load Available"] <- "Download Available"
sat3$`Direction Flag` <- rep(NA, nrow(sat3))
sat3$`Segment Count` <- rep(NA, nrow(sat3))
sat3$`Data Source` <- rep("declass3", nrow(sat3))
sat <- rbind(sat1_2, sat3)
write_csv(sat, "sat.csv")
View(sat)
# need to clean up coords n shit
sat1 <- read_csv("sat1.csv")
# need to clean up coords n shit
sat1 <- read_csv("sat1.csv")
sat2 <- read_csv("sat2.csv")
sat3 <- read_csv("sat3.csv")
View(sat1)
View(sat2)
dids <- unique(sat2$`Display ID`)
grepl("-", dids)
which(grepl("-", dids))
dids[17610]
dids[1]
dids[17610]
length(dids[17610])
nchar(dids[17610])
nchar(dids[1])
sat2 <- read_csv("sat2.csv")
dids <- unique(sat2$`Display ID`)
nchar(dids[1])
nchar(dids[17610])
dids[17610]
nchar(dids[1])
dids[1]
# reformat Display ID for sat1, sat2 due to bad formatting in CSV provided by USGS
reformat_id <- function(id, n) {
id <- strsplit(id, ",")[[1]][1] # split by comma, take first item
id
# this code inserted a "-", but I don't think that is actually necessary:
# # after the right n of characters insert "-"
# new_id <- paste(substr(id, 1, n), "-", substr(id, n+1, nchar(id)), sep = "")
# new_id
}
# need to clean up coords n shit
sat1 <- read_csv("sat1.csv")
sat2 <- read_csv("sat2.csv")
sat3 <- read_csv("sat3.csv")
# fix column inconsistencies
setdiff(colnames(sat2), colnames(sat1))
sat1$`Segment Count` <- rep(NA, nrow(sat1))
sat1$`Operations Number` <- rep(NA, nrow(sat1))
colnames(sat1)[colnames(sat1) == "NW Cormer Lat dec"] <- "NW Corner Lat dec"
sat1$`Data Source` <- rep("declass1", nrow(sat1))
setdiff(colnames(sat1), colnames(sat2))
sat2$`Direction Flag` <- rep(NA, nrow(sat2))
sat2$`Data Source` <- rep("declass2", nrow(sat2))
# reformat Display ID for sat1, sat2 due to bad formatting in CSV provided by USGS
reformat_id <- function(id, n) {
id <- strsplit(id, ",")[[1]][1] # split by comma, take first item
id
# this code inserted a "-", but I don't think that is actually necessary:
# # after the right n of characters insert "-"
# new_id <- paste(substr(id, 1, n), "-", substr(id, n+1, nchar(id)), sep = "")
# new_id
}
sat1$`Display ID` <- lapply(sat1$`Display ID`, reformat_id, n = 6)
sat2$`Display ID` <- lapply(sat2$`Display ID`, reformat_id, n = 7)
sat1_2 <- rbind(sat1,sat2)
setdiff(colnames(sat1_2), colnames(sat3))
sat3 <- sat3 %>%
mutate(`Camera Type` = str_replace(Camera, "A", "High Resolution Surveillance Camera - Aft")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "F", "High Resolution Surveillance Camera - Forward")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "T", "Lower Resolution Terrain Mapping Camera")) %>%
select(-Camera)
colnames(sat1_2)[colnames(sat1_2) == "Frame"] <- "Frame Number"
colnames(sat1_2)[colnames(sat1) == "Down Load Available"] <- "Download Available"
sat3$`Direction Flag` <- rep(NA, nrow(sat3))
sat3$`Segment Count` <- rep(NA, nrow(sat3))
sat3$`Data Source` <- rep("declass3", nrow(sat3))
sat <- rbind(sat1_2, sat3)
write_csv(sat, "sat.csv")
View(sat)
View(sat)
st_as_sf
?st_as_sf
?st_polygon
sat_test <- head(sat, 100)
st_as_sf(sat_test, coords = c("NW Corner Lat dec", "NW Corner Long dec", "NE Corner Long dec", "NE Corner Long dec", "SW Corner Lat dec", "SW Corner Long dec", "SE Corner Long dec", "SE Corner Long dec"))
sat_test <- sat_test %>%
mutate(geometry = paste("POLYGON ((", `NW Corner Lat dec`, " ", `NE Corner Lat dec` sep = ""))
sat_test <- sat_test %>%
mutate(geometry = paste("POLYGON ((", `NW Corner Lat dec`, " ", `NE Corner Lat dec` sep = "")))
sat_test <- sat_test %>%
mutate(geometry = paste("POLYGON ((", `NW Corner Lat dec`, " ", `NE Corner Lat dec`, sep = ""))
View(sat_test)
sat_test <- sat_test %>%
mutate(geometry = paste("POLYGON ((", `NW Corner Lat dec`, " ", `NW Corner Long dec`, ",",
`NE Corner Long dec`, " ", `NE Corner Long dec`, ",",
`SW Corner Lat dec`, " ", `SW Corner Long dec`, ",",
`SE Corner Long dec`, " ", `SE Corner Long dec`, "))", sep = ""))
sat_test$geometry[[1]]
sat <- sat %>%
mutate(geometry = paste("POLYGON ((",
`NW Corner Lat dec`, " ", `NW Corner Long dec`, ",",
`NE Corner Lat dec`, " ", `NE Corner Long dec`, ",",
`SE Corner Lat dec`, " ", `SE Corner Long dec`, ",",
`SW Corner Lat dec`, " ", `SW Corner Long dec`, "))", sep = ""))
View(sat_test)
sat_test <- sat_test[, -c(13:32)]
View(sat_test)
setdiff(colnames(sat), colnames(sat_test))
sat <- sat[, -c(13:32)]
sat_sf <- st_as_sf(sat, wkt = "geometry")
sat_sf <- sat_sf %>% mutate(polygon_geometry = geometry) # duplicate polygons because otherwise they'll be removed
facs <- read_csv("facilities.csv")[-1]
missiles <- read_csv("missiles.csv")[-1]
sat <- read_csv("sat.csv")[-1] # satellite photo polygons
# make wkt representation of sat geometry
sat <- sat %>%
mutate(geometry = paste("POLYGON ((",
`NW Corner Lat dec`, " ", `NW Corner Long dec`, ",",
`NE Corner Lat dec`, " ", `NE Corner Long dec`, ",",
`SE Corner Lat dec`, " ", `SE Corner Long dec`, ",",
`SW Corner Lat dec`, " ", `SW Corner Long dec`, "))", sep = ""))
sat <- sat[, -c(13:32)]
write_csv(sat, "sat.csv")
# Perform a spatial join to find points within polygons
fac_captures <- st_join(x = facs_sf, y = sat_sf, join = st_within)
# create Simple Features DFs
facs_sf <- st_as_sf(facs, coords = c("lng", "lat"), remove = FALSE)
# Perform a spatial join to find points within polygons
fac_captures <- st_join(x = facs_sf, y = sat_sf, join = st_within)
View(facs_sf)
View(sat_sf)
View(sat_sf[[17]][[1]])
test_sf <- st_as_sf(sat_test, wkt = "geometry")
test_captures <- st_join(x = facs_sf, y = sat_sf, join = st_within)
test_captures <- st_join(x = facs_sf, y = test_sf, join = st_within)
facs <- read_csv("facilities.csv")[-1]
missiles <- read_csv("missiles.csv")[-1]
# need to clean up coords n shit
sat1 <- read_csv("sat1.csv")
sat2 <- read_csv("sat2.csv")
sat3 <- read_csv("sat3.csv")
# fix column inconsistencies
setdiff(colnames(sat2), colnames(sat1))
sat1$`Segment Count` <- rep(NA, nrow(sat1))
sat1$`Operations Number` <- rep(NA, nrow(sat1))
colnames(sat1)[colnames(sat1) == "NW Cormer Lat dec"] <- "NW Corner Lat dec"
sat1$`Data Source` <- rep("declass1", nrow(sat1))
setdiff(colnames(sat1), colnames(sat2))
sat2$`Direction Flag` <- rep(NA, nrow(sat2))
sat2$`Data Source` <- rep("declass2", nrow(sat2))
# reformat Display ID for sat1, sat2 due to bad formatting in CSV provided by USGS
reformat_id <- function(id, n) {
id <- strsplit(id, ",")[[1]][1] # split by comma, take first item
id
# this code inserted a "-", but I don't think that is actually necessary:
# # after the right n of characters insert "-"
# new_id <- paste(substr(id, 1, n), "-", substr(id, n+1, nchar(id)), sep = "")
# new_id
}
sat1$`Display ID` <- lapply(sat1$`Display ID`, reformat_id, n = 6)
sat2$`Display ID` <- lapply(sat2$`Display ID`, reformat_id, n = 7)
sat1_2 <- rbind(sat1,sat2)
setdiff(colnames(sat1_2), colnames(sat3))
sat3 <- sat3 %>%
mutate(`Camera Type` = str_replace(Camera, "A", "High Resolution Surveillance Camera - Aft")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "F", "High Resolution Surveillance Camera - Forward")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "T", "Lower Resolution Terrain Mapping Camera")) %>%
select(-Camera)
colnames(sat1_2)[colnames(sat1_2) == "Frame"] <- "Frame Number"
colnames(sat1_2)[colnames(sat1) == "Down Load Available"] <- "Download Available"
sat3$`Direction Flag` <- rep(NA, nrow(sat3))
sat3$`Segment Count` <- rep(NA, nrow(sat3))
sat3$`Data Source` <- rep("declass3", nrow(sat3))
sat <- rbind(sat1_2, sat3)
# make wkt representation of sat geometry
sat <- sat %>%
mutate(geometry = paste("POLYGON ((",
`NW Corner Lat dec`, " ", `NW Corner Long dec`, ",",
`NE Corner Lat dec`, " ", `NE Corner Long dec`, ",",
`SE Corner Lat dec`, " ", `SE Corner Long dec`, ",",
`SW Corner Lat dec`, " ", `SW Corner Long dec`, ",",
`NW Corner Lat dec`, " ", `NW Corner Long dec`, "))", sep = ""))
sat <- sat[, -c(13:32)]
write_csv(sat, "sat.csv")
sat_test <- head(sat, 100)
test_sf <- st_as_sf(sat_test, wkt = "geometry")
test_sf <- st_as_sf(sat_test, wkt = "geometry")
test_captures <- st_join(x = facs_sf, y = test_sf, join = st_within)
View(test_sf)
View(test_captures)
# create Simple Features DFs
facs_sf <- st_as_sf(facs, coords = c("lng", "lat"), remove = FALSE)
miss_sf <- st_as_sf(missiles, coords = c("lng", "lat"), remove = FALSE)
sat_sf <- st_as_sf(sat, wkt = "geometry")
sat_sf <- sat_sf %>% mutate(polygon_geometry = geometry) # duplicate polygons because otherwise they'll be removed
# Perform a spatial join to find points within polygons
fac_captures <- st_join(x = facs_sf, y = sat_sf, join = st_within)
# convert SF geometry columns to characters to avoid CSV file formatting issues
fac_captures$geometry <- st_as_text(fac_captures$geometry)
fac_captures$polygon_geometry <- st_as_text(fac_captures$polygon_geometry)
# filter the dataset to remove cases where the photo was taken before construction started
fac_captures <- fac_captures %>%
filter(start_date <= `Acquisition Date`) %>%
as.data.frame() # convert from SF back to regular DF
write.csv(fac_captures, "fac_captures.csv")
View(fac_captures)
# Use sapply to get column data types
column_types <- sapply(df, class)
# Print the column data types
print(column_types)
# Use sapply to get column data types
column_types <- sapply(fac_captures, class)
# Print the column data types
print(column_types)
fac_captures$`Display ID` <- as.character(fac_captures$`Display ID`)
# Use sapply to get column data types
column_types <- sapply(fac_captures, class)
# Print the column data types
print(column_types)
write.csv(fac_captures, "fac_captures.csv")
# Perform a spatial join to find points within polygons
miss_captures <- st_join(x = miss_sf, y = sat_sf, join = st_within)
# convert SF geometry columns to characters to avoid CSV file formatting issues
miss_captures$geometry <- st_as_text(miss_captures$geometry)
miss_captures$polygon_geometry <- st_as_text(miss_captures$polygon_geometry)
# filter the dataset to remove cases where the photo was taken before construction started
miss_captures <- miss_captures %>%
filter(start_date <= `Acquisition Date`,
ifelse(!is.na(end_date), end_date >= `Acquisition Date`, TRUE)) %>%
as.data.frame() # convert from SF back to regular DF
miss_captures$`Display ID` <- as.character(miss_captures$`Display ID`)
write.csv(miss_captures, "miss_captures.csv")
shiny::runApp()
library(xlsx)
library(tidyverse)
library(sf)
# need to clean up coords n shit
sat1 <- read_csv("sat1.csv")
sat2 <- read_csv("sat2.csv")
sat3 <- read_csv("sat3.csv")
# fix column inconsistencies
setdiff(colnames(sat2), colnames(sat1))
sat1$`Segment Count` <- rep(NA, nrow(sat1))
sat1$`Operations Number` <- rep(NA, nrow(sat1))
colnames(sat1)[colnames(sat1) == "NW Cormer Lat dec"] <- "NW Corner Lat dec"
sat1$`Data Source` <- rep("declass1", nrow(sat1))
setdiff(colnames(sat1), colnames(sat2))
sat2$`Direction Flag` <- rep(NA, nrow(sat2))
sat2$`Data Source` <- rep("declass2", nrow(sat2))
# reformat Display ID for sat1, sat2 due to bad formatting in CSV provided by USGS
reformat_id <- function(id, n) {
id <- strsplit(id, ",")[[1]][1] # split by comma, take first item
id
# this code inserted a "-", but I don't think that is actually necessary:
# # after the right n of characters insert "-"
# new_id <- paste(substr(id, 1, n), "-", substr(id, n+1, nchar(id)), sep = "")
# new_id
}
sat1$`Display ID` <- lapply(sat1$`Display ID`, reformat_id, n = 6)
sat2$`Display ID` <- lapply(sat2$`Display ID`, reformat_id, n = 7)
sat1_2 <- rbind(sat1,sat2)
setdiff(colnames(sat1_2), colnames(sat3))
sat3 <- sat3 %>%
mutate(`Camera Type` = str_replace(Camera, "A", "High Resolution Surveillance Camera - Aft")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "F", "High Resolution Surveillance Camera - Forward")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "T", "Lower Resolution Terrain Mapping Camera")) %>%
select(-Camera)
colnames(sat1_2)[colnames(sat1_2) == "Frame"] <- "Frame Number"
colnames(sat1_2)[colnames(sat1) == "Down Load Available"] <- "Download Available"
sat3$`Direction Flag` <- rep(NA, nrow(sat3))
sat3$`Segment Count` <- rep(NA, nrow(sat3))
sat3$`Data Source` <- rep("declass3", nrow(sat3))
sat <- rbind(sat1_2, sat3)
# make wkt representation of sat geometry
sat <- sat %>%
mutate(geometry = paste("POLYGON ((",
`NW Corner Long dec`, " ", `NW Corner Lat dec`, ",",
`NE Corner Long dec`, " ", `NE Corner Lat dec`, ",",
`SE Corner Long dec`, " ", `SE Corner Lat dec`, ",",
`SW Corner Long dec`, " ", `SW Corner Lat dec`, ",",
`NW Corner Long dec`, " ", `NW Corner Lat dec`, "))", sep = ""))
sat <- sat[, -c(13:32)]
write_csv(sat, "sat.csv")
facs <- read_csv("facilities.csv")[-1]
missiles <- read_csv("missiles.csv")[-1]
sat <- read_csv("sat.csv")[-1] # satellite photo polygons
# create Simple Features DFs
facs_sf <- st_as_sf(facs, coords = c("lng", "lat"), remove = FALSE)
miss_sf <- st_as_sf(missiles, coords = c("lng", "lat"), remove = FALSE)
sat_sf <- st_as_sf(sat, wkt = "geometry")
sat_sf <- sat_sf %>% mutate(polygon_geometry = geometry) # duplicate polygons because otherwise they'll be removed
# Perform a spatial join to find points within polygons
fac_captures <- st_join(x = facs_sf, y = sat_sf, join = st_within)
# convert SF geometry columns to characters to avoid CSV file formatting issues
fac_captures$geometry <- st_as_text(fac_captures$geometry)
fac_captures$polygon_geometry <- st_as_text(fac_captures$polygon_geometry)
# filter the dataset to remove cases where the photo was taken before construction started
fac_captures <- fac_captures %>%
filter(start_date <= `Acquisition Date`) %>%
as.data.frame() # convert from SF back to regular DF
fac_captures$`Display ID` <- as.character(fac_captures$`Display ID`)
write.csv(fac_captures, "fac_captures.csv")
# Perform a spatial join to find points within polygons
miss_captures <- st_join(x = miss_sf, y = sat_sf, join = st_within)
# convert SF geometry columns to characters to avoid CSV file formatting issues
miss_captures$geometry <- st_as_text(miss_captures$geometry)
miss_captures$polygon_geometry <- st_as_text(miss_captures$polygon_geometry)
# filter the dataset to remove cases where the photo was taken before construction started
miss_captures <- miss_captures %>%
filter(start_date <= `Acquisition Date`,
ifelse(!is.na(end_date), end_date >= `Acquisition Date`, TRUE)) %>%
as.data.frame() # convert from SF back to regular DF
miss_captures$`Display ID` <- as.character(miss_captures$`Display ID`)
write.csv(miss_captures, "miss_captures.csv")
runApp()
View(sat)
sat_test <- head(sat,1000)
# need to clean up coords n shit
sat1 <- read_csv("sat1.csv")
sat1 <- read_csv("sat1.csv")
sat2 <- read_csv("sat2.csv")
sat3 <- read_csv("sat3.csv")
# need to clean up coords n shit
sat1 <- read_csv("sat1.csv")
sat2 <- read_csv("sat2.csv")
sat3 <- read_csv("sat3.csv")
# fix column inconsistencies
setdiff(colnames(sat2), colnames(sat1))
sat1$`Segment Count` <- rep(NA, nrow(sat1))
sat1$`Operations Number` <- rep(NA, nrow(sat1))
colnames(sat1)[colnames(sat1) == "NW Cormer Lat dec"] <- "NW Corner Lat dec"
sat1$`Data Source` <- rep("declass1", nrow(sat1))
setdiff(colnames(sat1), colnames(sat2))
sat2$`Direction Flag` <- rep(NA, nrow(sat2))
sat2$`Data Source` <- rep("declass2", nrow(sat2))
# reformat Display ID for sat1, sat2 due to bad formatting in CSV provided by USGS
reformat_id <- function(id, n) {
id <- strsplit(id, ",")[[1]][1] # split by comma, take first item
id
# this code inserted a "-", but I don't think that is actually necessary:
# # after the right n of characters insert "-"
# new_id <- paste(substr(id, 1, n), "-", substr(id, n+1, nchar(id)), sep = "")
# new_id
}
sat1$`Display ID` <- lapply(sat1$`Display ID`, reformat_id, n = 6)
sat2$`Display ID` <- lapply(sat2$`Display ID`, reformat_id, n = 7)
sat1_2 <- rbind(sat1,sat2)
setdiff(colnames(sat1_2), colnames(sat3))
sat3 <- sat3 %>%
mutate(`Camera Type` = str_replace(Camera, "A", "High Resolution Surveillance Camera - Aft")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "F", "High Resolution Surveillance Camera - Forward")) %>%
mutate(`Camera Type` = str_replace(`Camera Type`, "T", "Lower Resolution Terrain Mapping Camera")) %>%
select(-Camera)
colnames(sat1_2)[colnames(sat1_2) == "Frame"] <- "Frame Number"
colnames(sat1_2)[colnames(sat1) == "Down Load Available"] <- "Download Available"
sat3$`Direction Flag` <- rep(NA, nrow(sat3))
sat3$`Segment Count` <- rep(NA, nrow(sat3))
sat3$`Data Source` <- rep("declass3", nrow(sat3))
sat <- rbind(sat1_2, sat3)
View(sat)
sat <- sat %>%
mutate(geometry = paste("POLYGON ((",
`NW Corner Long dec`, " ", `NW Corner Lat dec`, ",",
`NE Corner Long dec`, " ", `NE Corner Lat dec`, ",",
`SE Corner Long dec`, " ", `SE Corner Lat dec`, ",",
`SW Corner Long dec`, " ", `SW Corner Lat dec`, ",",
`NW Corner Long dec`, " ", `NW Corner Lat dec`, "))", sep = ""))
sat <- sat[, -c(13:32)]
View(sat)
write_csv(sat, "sat.csv")
sat_read <- read_csv2("sat.csv")
View(sat_read)
sat_read <- read_csv("sat.csv")
View(sat)
View(sat_read)
View(sat)
sat$`Display ID` <- as.character(sat$`Display ID`)
write_csv(sat, "sat.csv")
sat_read <- read_csv("sat.csv")
get_pic_URL <- function(declass_n, mission, direc_flag, cam_type, disp_ID) {
# declass1
url <- "broken link"
# https://ims.cr.usgs.gov/browse/DIT/1117-2/086D/A/DS1117-2086DA001.jpg
# https://ims.cr.usgs.gov/browse/DIT/Mission/`Direction Flag`/`Camera Type`(V/F/A)/`Display ID`.jpg
if (declass_n == "declass1") {
cam_letter <- recode(cam_type,
"Vertical" = "V",
"Aft" = "A",
"Cartographic" = "C",
"Forward" = "F"
)
url <- paste("https://ims.cr.usgs.gov/browse/DIT/", mission, "/", direc_flag, "/", cam_letter,"/", disp_ID, ".jpg", sep = "")
}
url
}
runApp()
runApp()
runApp()
View(sat)
View(sat_read)
runApp()
facs <- read_csv("facilities.csv")[-1]
missiles <- read_csv("missiles.csv")[-1]
sat <- read_csv("sat.csv")[-1] # satellite photo polygons
# create Simple Features DFs
facs_sf <- st_as_sf(facs, coords = c("lng", "lat"), remove = FALSE)
miss_sf <- st_as_sf(missiles, coords = c("lng", "lat"), remove = FALSE)
sat_sf <- st_as_sf(sat, wkt = "geometry")
sat_sf <- sat_sf %>% mutate(polygon_geometry = geometry) # duplicate polygons because otherwise they'll be removed
# Perform a spatial join to find points within polygons
fac_captures <- st_join(x = facs_sf, y = sat_sf, join = st_within)
# convert SF geometry columns to characters to avoid CSV file formatting issues
fac_captures$geometry <- st_as_text(fac_captures$geometry)
fac_captures$polygon_geometry <- st_as_text(fac_captures$polygon_geometry)
# filter the dataset to remove cases where the photo was taken before construction started
fac_captures <- fac_captures %>%
filter(start_date <= `Acquisition Date`) %>%
as.data.frame() # convert from SF back to regular DF
# fac_captures$`Display ID` <- as.character(fac_captures$`Display ID`) # this should be unec.
write.csv(fac_captures, "fac_captures.csv")
# Perform a spatial join to find points within polygons
miss_captures <- st_join(x = miss_sf, y = sat_sf, join = st_within)
# convert SF geometry columns to characters to avoid CSV file formatting issues
miss_captures$geometry <- st_as_text(miss_captures$geometry)
miss_captures$polygon_geometry <- st_as_text(miss_captures$polygon_geometry)
# filter the dataset to remove cases where the photo was taken before construction started
miss_captures <- miss_captures %>%
filter(start_date <= `Acquisition Date`,
ifelse(!is.na(end_date), end_date >= `Acquisition Date`, TRUE)) %>%
as.data.frame() # convert from SF back to regular DF
# miss_captures$`Display ID` <- as.character(miss_captures$`Display ID`) # this should be unec.
write.csv(miss_captures, "miss_captures.csv")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?addCircleMarkers
runApp()
1:0
1:10
runApp()
runApp()
runApp()
runApp()
?a
runApp()
runApp()
runApp()
runApp()
?titlePanel
runApp()
runApp()
runApp()
runApp()
?h4
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
